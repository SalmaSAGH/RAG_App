# ğŸŒ RAG Demo â€” IPCC AR6  
### Retrieval-Augmented Generation with Ollama + LangChain + FastAPI + Streamlit

---

## ğŸ“Œ Description du Projet

Ce projet implÃ©mente une application RAG (Retrieval-Augmented Generation) permettant dâ€™interroger localement les rapports climatiques IPCC AR6 grÃ¢ce Ã  un modÃ¨le LLM exÃ©cutÃ© via **Ollama**.  
Le systÃ¨me combine :

- extraction et dÃ©coupage de PDF  
- embeddings avec un modÃ¨le local  
- base vectorielle Chroma  
- pipeline RAG complet  
- backend FastAPI  
- interface utilisateur Streamlit  

Lâ€™objectif est dâ€™illustrer un pipeline RAG simple, local et reproductible.

---

## ğŸ“ Structure du Projet

```
project/
â”‚â”€â”€ data/               # PDF IPCC AR6
â”‚â”€â”€ chunks/             # Chunks gÃ©nÃ©rÃ©s automatiquement
â”‚â”€â”€ vectordb/           # Base vectorielle persistÃ©e
â”‚â”€â”€ ingest.py           # Extraction & chunking des PDFs
â”‚â”€â”€ embeddings.py       # Embeddings + stockage vecteur
â”‚â”€â”€ app.py              # Backend FastAPI (RAG)
â”‚â”€â”€ ui_streamlit.py     # Interface Streamlit
â”‚â”€â”€ requirements.txt    # DÃ©pendances Python
â”‚â”€â”€ README.md           # Ce fichier
```

---

## ğŸ§© FonctionnalitÃ©s

- Extraction automatique du texte des PDFs AR6  
- DÃ©coupage intelligent en chunks (1000 caractÃ¨res, overlap 200)  
- Embeddings locaux via *nomic-embed-text*  
- Recherche vectorielle Chroma  
- Pipeline RAG : Retriever + Prompt + LLM (llama3.2:1b)  
- RÃ©ponses accompagnÃ©es des sources (PDF + page)  
- Interface Streamlit conviviale  

---

## ğŸ› ï¸ PrÃ©requis

- Python **3.10+**
- **Ollama** installÃ© (https://ollama.com/)
- ModÃ¨les Ollama nÃ©cessaires :
  ```
  ollama pull llama3.2:1b
  ollama pull nomic-embed-text
  ```
- PDF AR6 placÃ©s dans le dossier `data/`

---

## ğŸš€ Installation

### 1ï¸âƒ£ Cloner le projet
```
git clone https://github.com/<your-username>/<your-repo>.git
cd <your-repo>
```

### 2ï¸âƒ£ CrÃ©er lâ€™environnement Python
```
python -m venv .venv
source .venv/bin/activate   # Windows: .venv\Scripts\activate
```

### 3ï¸âƒ£ Installer les dÃ©pendances
```
pip install -r requirements.txt
```

### 4ï¸âƒ£ Lancer le daemon Ollama
```
ollama serve &
```

---

## ğŸ“¥ Ã‰tape 1 : Ingestion des PDFs
```
python ingest.py
```

---

## ğŸ§  Ã‰tape 2 : GÃ©nÃ©ration des embeddings
```
python embeddings.py
```

---

## ğŸ§© Ã‰tape 3 : Lancer le backend FastAPI
```
uvicorn app:app --reload --port 8000
```

AccÃ¨s API :  
â¡ï¸ http://localhost:8000/docs

---

## ğŸ¨ Ã‰tape 4 : Lancer lâ€™interface Streamlit
```
streamlit run ui_streamlit.py
```

---

## ğŸ§ª Exemples de Questions

- What is the main cause of climate change?  
- What does the AR6 SPM say about sea level rise?  
- Do greenhouse gas emissions need to increase or decrease?

---

## ğŸ“š Rapport inclus

Le projet est accompagnÃ© dâ€™un rapport dÃ©taillant :

- les choix techniques (chunk size, embeddings, retrieverâ€¦)  
- les rÃ©sultats obtenus  
- le fonctionnement global du pipeline RAG  

---

## ğŸ§­ Limitations et Travaux futurs

- AmÃ©lioration du prompt  
- Ajout dâ€™un re-ranker  
- Ajout dâ€™un systÃ¨me de feedback utilisateur  
- UI plus avancÃ©e en React  
- Comparaison avec LlamaIndex  

---

## ğŸ‘©â€ğŸ’» Auteur
Ton nom ici

---

